# Python CircleCI 2.0 configuration file
#
# Check https://circleci.com/docs/2.0/language-python/ for more details
#
version: 2.1

commands:
  install:
    description: "Installs the necessary packages"
    steps:
      # Download and cache dependencies
      - restore_cache:
          keys:
            - v1-dependencies-{{ checksum "requirements.txt" }}
            # fallback to using the latest cache if no exact match is found
            - v1-dependencies-

      - run:
          name: install dependencies
          command: |
            python -m venv venv
            . venv/bin/activate
            pip install --upgrade pip
            pip install -r requirements.txt
            pip install -r requirements-dev.txt
            if
              [ ${CIRCLE_JOB} == "docs" ]
            then
              pip install -r requirements-doc.txt
            fi
            if
              [ ${CIRCLE_JOB} == "benchmark" ]
            then
              pip install virtualenv==16.7.9
              pip install git+https://github.com/airspeed-velocity/asv
            fi

      - run:
          name: Setup Code Climate test-reporter
          command: |
            # download test reporter as a static binary
            curl -L https://codeclimate.com/downloads/test-reporter/test-reporter-latest-linux-amd64 > ./cc-test-reporter
            chmod +x ./cc-test-reporter

      - run:
          name: Setup codacy reporter
          command: |
            python -m venv venv
            . venv/bin/activate
            pip install codacy-coverage

      - save_cache:
          paths:
            - ./venv
            - cc-test-reporter
          key: v1-dependencies-{{ checksum "requirements.txt" }}

  test:
    description: "Run the tests"
    steps:
      - run:
          name: run tests
          command: |
            . venv/bin/activate
            export CODACY_PROJECT_TOKEN=819af61c85004229a83cb34b8089930c
            export CC_TEST_REPORTER_ID=8b40c7b919b1734ebd87f91c3033557f84b8c737db91057bdf75d16251440c59
            ./cc-test-reporter before-build
            make test
            ./cc-test-reporter after-build --coverage-input-type coverage.py --exit-code $?
            python-codacy-coverage -r coverage.xml
            mkdir -p test_reports/neurolang
            cp utest.xml test_reports/neurolang/results.xml

      - store_artifacts:
          when: always
          path: test_reports
          destination: test_reports
      - store_test_results:
          path: test_reports
          when: always


jobs:
  py36:
    docker:
      - image: circleci/python:3.6

    working_directory: ~/repo
    steps:
      - checkout
      - install
      - test

  py37:
    docker:
      - image: circleci/python:3.7

    working_directory: ~/repo

    steps:
      - checkout
      - install
      - test

  benchmark:
    docker:
      - image: circleci/python:3.7

    working_directory: ~/repo

    steps:
      - checkout
      - install
      - run:
          name: Install ASV & run benchmark
          command: |
            . venv/bin/activate
            asv machine --yes
            if 
              [ "${CIRCLE_BRANCH}" = "master" ]
            then
              asv run -v $(git rev-parse HEAD)...$(git rev-parse HEAD~5)
              export RESULT=$?
            else
              asv continuous --strict -v $(git rev-parse master) $(git rev-parse HEAD)
              export RESULT=$?
            fi
            asv publish
            if 
              [ $RESULT -ne 0 ]
            then
              exit 1
            fi
          no_output_timeout: 1h
      - store_artifacts:
          path: .asv/html
          destination: benchmarks

  docs:
    docker:
      - image: circleci/python:3.7

    working_directory: ~/repo

    steps:
      - checkout
      - install
      - run:
          name: Install extra packages & build documentation
          command: |
            . venv/bin/activate
            cd doc
            make html
          no_output_timeout: 7h
      - store_artifacts:
          path: doc/_build/html


workflows:
  version: 2
  test_benchmark_build:
    jobs:
      - py36
      - py37
      - benchmark:
          requires:
            - py37
#      - docs:
#          requires:
#            - benchmark
