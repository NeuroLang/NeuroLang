{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/nilearn/plotting/cm.py:159: MatplotlibDeprecationWarning: \n",
      "The revcmap function was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use Colormap.reversed() instead.\n",
      "  _cmaps_data[_cmapname_r] = _cm.revcmap(_cmapspec)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/tatsu/grammars.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import defaultdict, Mapping\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/problog/util.py:250: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  class OrderedSet(collections.MutableSet):\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/mask.py:232: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  return self.volume.get_header()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:624: FutureWarning: DataFrame/Series.to_dense is deprecated and will be removed in a future version\n",
      "  old_data = self.data.to_dense()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:634: FutureWarning: DataFrame.to_sparse is deprecated and will be removed in a future version\n",
      "  self.data = data.fillna(0.0).to_sparse()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/mask.py:232: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  return self.volume.get_header()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:624: FutureWarning: DataFrame/Series.to_dense is deprecated and will be removed in a future version\n",
      "  old_data = self.data.to_dense()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:634: FutureWarning: DataFrame.to_sparse is deprecated and will be removed in a future version\n",
      "  self.data = data.fillna(0.0).to_sparse()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/numpy/lib/npyio.py:2358: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  output = genfromtxt(fname, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import stats_helper, datasets_helper\n",
    "from neurolang.frontend.probabilistic_frontend import ProbabilisticFrontend\n",
    "from rdflib import RDFS\n",
    "from nilearn import plotting\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Iterable\n",
    "from neurolang import frontend as fe\n",
    "\n",
    "nl = ProbabilisticFrontend()\n",
    "datasets_helper.load_reverse_inference_dataset(nl)\n",
    "\n",
    "path = 'neurolang_data/ontologies/cogat.xrdf'\n",
    "nl.load_ontology(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_of = nl.new_symbol(name='http://www.obofoundry.org/ro/ro.owl#part_of')\n",
    "subclass_of = nl.new_symbol(name=str(RDFS.subClassOf))\n",
    "label = nl.new_symbol(name=str(RDFS.label))\n",
    "hasTopConcept = nl.new_symbol(name='http://www.w3.org/2004/02/skos/core#hasTopConcept')\n",
    "\n",
    "@nl.add_symbol\n",
    "def word_lower(name: str) -> str:\n",
    "    print(name)\n",
    "    return str(name).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "λ{C{word_lower: typing.Callable[[str], str]}: str}(C{'name': ColumnStr})\n",
      "λ{C{word_lower: typing.Callable[[str], str]}: str}(C{'name': ColumnStr})\n",
      "λ{C{word_lower: typing.Callable[[str], str]}: str}(C{'name': ColumnStr})\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "λ{C{word_lower: typing.Callable[[str], str]}: str}(C{'name': ColumnStr})\n",
      "λ{C{word_lower: typing.Callable[[str], str]}: str}(C{'name': ColumnStr})\n",
      "λ{C{word_lower: typing.Callable[[str], str]}: str}(C{'name': ColumnStr})\n",
      "λ{C{word_lower: typing.Callable[[str], str]}: str}(C{'name': ColumnStr})\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "λ{C{word_lower: typing.Callable[[str], str]}: str}(C{'name': ColumnStr})\n"
     ]
    }
   ],
   "source": [
    "from operator import eq\n",
    "\n",
    "with nl.scope as e:\n",
    "    #e.julich_to_neurosynth[e.julich_id, e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "    #    e.xyz_julich[e.x, e.y, e.z, e.julich_id] &\n",
    "    #    e.xyz_neurosynth[e.x, e.y, e.z, e.id_neurosynth]\n",
    "    #)\n",
    "    \n",
    "    #e.region_voxels[e.name, e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "    #    e.julich_id[e.name, e.julich_id] &\n",
    "    #    e.julich_to_neurosynth[e.julich_id, e.id_neurosynth, e.x, e.y, e.z]\n",
    "    #)\n",
    "    \n",
    "    #e.julich_id[e.name, e.id] = (\n",
    "    #    e.julich_ontology[e.name, 'labelIndex', e.id]\n",
    "    #)\n",
    "    \n",
    "    #e.julich_voxels[e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "    #    e.region_voxels['Area Ia (Insula)', e.id_neurosynth, e.x, e.y, e.z]\n",
    "    #)\n",
    "    \n",
    "    #e.p_act[e.id_voxel, e.term] = (\n",
    "    #    e.p_voxel_study[e.id_voxel, e.id_study] & \n",
    "    #    e.p_term_study[e.term,  e.id_study] & \n",
    "    #    e.p_study[e.id_study]\n",
    "    #)\n",
    "    \n",
    "    e.ontology_terms[e.lower] = (\n",
    "        hasTopConcept[e.uri, 'Executive-Cognitive Control'] &\n",
    "        label[e.uri, e.name] &\n",
    "        (e.lower == word_lower(e.name))\n",
    "    )\n",
    "    \n",
    "    #e.probability_voxel[e.term] = (\n",
    "    #    e.p_act[e.id_voxel, e.term] &\n",
    "    #    e.julich_voxels[e.id_voxel, e.x, e.y, e.z] &\n",
    "    #    e.ontology_terms[e.term]\n",
    "    #)\n",
    "    \n",
    "    nl_results = nl.solve_query(e.ontology_terms[e.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C{     0\n",
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "5    5\n",
       "6    6\n",
       "7    7\n",
       "8    8\n",
       "9    9\n",
       "10  10\n",
       "11  11\n",
       "12  12\n",
       "13  13\n",
       "14  14\n",
       "15  15\n",
       "16  16\n",
       "17  17\n",
       "18  18\n",
       "19  19\n",
       "20  20\n",
       "21  21\n",
       "22  22\n",
       "23  23\n",
       "24  24\n",
       "25  25\n",
       "26  26\n",
       "27  27\n",
       "28  28\n",
       "29  29\n",
       "30  30\n",
       "31  31\n",
       "32  32\n",
       "33  33\n",
       "34  34\n",
       "35  35\n",
       "36  36\n",
       "37  37\n",
       "38  38\n",
       "39  39\n",
       "40  40\n",
       "41  41: typing.AbstractSet[typing.Tuple[str]]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl_results['ontology_terms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "neurolang",
   "language": "python",
   "name": "neurolang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
