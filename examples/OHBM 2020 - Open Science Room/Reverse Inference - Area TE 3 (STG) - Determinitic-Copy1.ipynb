{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse inference - Example without using ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/nilearn/plotting/cm.py:159: MatplotlibDeprecationWarning: \n",
      "The revcmap function was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use Colormap.reversed() instead.\n",
      "  _cmaps_data[_cmapname_r] = _cm.revcmap(_cmapspec)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/tatsu/grammars.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import defaultdict, Mapping\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/problog/util.py:250: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  class OrderedSet(collections.MutableSet):\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import stats_helper, datasets_helper\n",
    "from neurolang.frontend.probabilistic_frontend import ProbabilisticFrontend\n",
    "from rdflib import RDFS\n",
    "from nilearn import plotting\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Iterable\n",
    "from neurolang import frontend as fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/mask.py:232: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  return self.volume.get_header()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:624: FutureWarning: DataFrame/Series.to_dense is deprecated and will be removed in a future version\n",
      "  old_data = self.data.to_dense()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:634: FutureWarning: DataFrame.to_sparse is deprecated and will be removed in a future version\n",
      "  self.data = data.fillna(0.0).to_sparse()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:3451: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  return klass(values, index=self.index, name=items, fastpath=True)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:450: ResourceWarning: unclosed file <_io.BufferedWriter name='neurolang_data/neurosynth/dataset.pkl'>\n",
      "  pickle.dump(self, open(filename, 'wb'), -1)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:771: FutureWarning: DataFrame.to_sparse is deprecated and will be removed in a future version\n",
      "  columns=self.data['columns']).to_sparse()\n"
     ]
    }
   ],
   "source": [
    "nl = fe.NeurolangDL()\n",
    "datasets_helper.load_reverse_inference_dataset_deterministic(nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nl.add_symbol\n",
    "def agg_count(x: Iterable) -> int:\n",
    "    return len(x)\n",
    "\n",
    "@nl.add_symbol\n",
    "def agg_sum(x: Iterable) -> float:\n",
    "    return x.sum()\n",
    "\n",
    "@nl.add_symbol\n",
    "def agg_mean(x: Iterable) -> float:\n",
    "    return x.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing julich atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nl.scope as e:\n",
    "    \n",
    "    e.julich_to_neurosynth[e.julich_id, e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.xyz_julich[e.x, e.y, e.z, e.julich_id] &\n",
    "        e.xyz_neurosynth[e.x, e.y, e.z, e.id_neurosynth]\n",
    "    )\n",
    "    \n",
    "    e.region_voxels[e.name, e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.julich_id[e.name, e.julich_id] &\n",
    "        e.julich_to_neurosynth[e.julich_id, e.id_neurosynth, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    e.julich_id[e.name, e.id] = (\n",
    "        e.julich_ontology[e.name, 'labelIndex', e.id]\n",
    "    )\n",
    "    \n",
    "    e.julich_voxels[e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.region_voxels['Area TE 3 (STG)', e.id_neurosynth, e.x, e.y, e.z]\n",
    "        \n",
    "    )\n",
    "    \n",
    "    nl_results = nl.solve_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_region(x, y, z, img):\n",
    "    voxels = nib.affines.apply_affine(\n",
    "        np.linalg.inv(img.affine), np.c_[x, y, z]\n",
    "    )\n",
    "    return fe.ExplicitVBR(voxels, img.affine, image_dim=img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/mask.py:232: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  return self.volume.get_header()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-aac44363d04c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnsh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneurosynth_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNeuroSynthHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mns_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mns_load_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mns_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/frontend/neurosynth_utils.py\u001b[0m in \u001b[0;36mns_load_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m\"Downloading neurosynth database\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         )\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_ns_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/frontend/neurosynth_utils.py\u001b[0m in \u001b[0;36mdownload_ns_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m         )\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_neurosynth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_neurosynth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_neurosynth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dataset.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, feature_filename, masker, r, transform, target, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Create supporting tables for images and features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_image_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_filename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py\u001b[0m in \u001b[0;36mcreate_image_table\u001b[0;34m(self, r)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     def get_studies(self, features=None, expression=None, mask=None,\n",
      "\u001b[0;32m~/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, r, use_sparse)\u001b[0m\n\u001b[1;32m    490\u001b[0m             img = imageutils.map_peaks_to_image(\n\u001b[1;32m    491\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'j'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'k'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m                 header=self.masker.get_header())\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mimg_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muse_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/imageutils.py\u001b[0m in \u001b[0;36mmap_peaks_to_image\u001b[0;34m(peaks, r, vox_dims, dims, header)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sphere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvox_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnifti1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNifti1Image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from neurolang.regions import region_union\n",
    "import nibabel as nib\n",
    "from nilearn import image\n",
    "\n",
    "results = nl_results['julich_voxels'].unwrapped_iter()\n",
    "\n",
    "nsh = fe.neurosynth_utils.NeuroSynthHandler()\n",
    "ns_ds = nsh.ns_load_dataset()\n",
    "it = ns_ds.image_table\n",
    "\n",
    "regions = []\n",
    "vox_prob = []\n",
    "\n",
    "atlas_r_filename = './22/MPM/JulichBrain_MPMAtlas_r_N10_nlin2Stdicbm152asym2009c_publicDOI_14622b49a715338ce96e96611d395646.nii.gz'\n",
    "img_r = image.load_img(atlas_r_filename)\n",
    "julich_to_ns_mni = image.resample_to_img(\n",
    "    img_r, it.masker.volume, interpolation=\"nearest\"\n",
    ")\n",
    "\n",
    "for id_, x, y, z in results:\n",
    "    r_overlay = create_region(x, y, z, julich_to_ns_mni)\n",
    "    vox_prob.append((r_overlay.voxels, 1))\n",
    "    regions.append(r_overlay)\n",
    "\n",
    "regions = region_union(regions)\n",
    "\n",
    "prob_img = nib.spatialimages.SpatialImage(\n",
    "    np.zeros(regions.image_dim, dtype=float), affine=regions.affine\n",
    ")\n",
    "for v, p in vox_prob:\n",
    "    prob_img.dataobj[tuple(v.T)] = p\n",
    "\n",
    "#plotting.plot_stat_map(\n",
    "#    prob_img, \n",
    "    #title='Tag \"auditory\" (Neurolang)', \n",
    "    #bg_img='/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/resources/MNI152_T1_2mm_brain.nii.gz',\n",
    "#    cmap='PuBuGn',\n",
    "#    display_mode='x',\n",
    "#    cut_coords=np.linspace(-63, 63, 4),\n",
    "#)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fg = plt.figure(figsize=(6, 6))\n",
    "plotting.plot_roi(prob_img, figure=fg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/Projects/INRIA/NeuroLang/neurolang/datalog/aggregation.py:152: UserWarning: No check performed. Should implement check for stratified aggregation\n",
      "  \"No check performed. Should implement check for stratified\"\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:4218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:4218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:4218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "with nl.scope as e:\n",
    "    e.julich_to_neurosynth[e.julich_id, e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.xyz_julich[e.x, e.y, e.z, e.julich_id] &\n",
    "        e.xyz_neurosynth[e.x, e.y, e.z, e.id_neurosynth]\n",
    "    )\n",
    "    \n",
    "    e.region_voxels[e.name, e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.julich_id[e.name, e.julich_id] &\n",
    "        e.julich_to_neurosynth[e.julich_id, e.id_neurosynth, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    e.julich_id[e.name, e.id] = (\n",
    "        e.julich_ontology[e.name, 'labelIndex', e.id]\n",
    "    )\n",
    "    \n",
    "    #e.julich_id[e.name, e.id] = (\n",
    "    #    e.julich_ontology[e.name, 'subClassOf', e.son_name] &\n",
    "    #    e.julich_id[e.son_name, e.id]\n",
    "    #)\n",
    "    \n",
    "    e.julich_voxels[e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.region_voxels['Area TE 3 (STG)', e.id_neurosynth, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    e.term_docs[e.term, e.pmid] = (\n",
    "        e.ns_pmid_term_tfidf[e.pmid, e.term, e.tfidf] &\n",
    "        (e.tfidf > 1e-3)        \n",
    "    )\n",
    "\n",
    "    e.term_counts[e.term, agg_count(e.pmid)] =  (\n",
    "        e.ns_pmid_term_tfidf[e.pmid, e.term, e.tfidf] &\n",
    "        e.term_docs[e.term, e.pmid]\n",
    "    )\n",
    "    e.act_counts[e.voxid, agg_count(e.pmid)] = e.ns_activations_by_id[e.pmid, e.voxid]\n",
    "    \n",
    "    e.quantity_docs[agg_count(e.pmid)] = e.ns_pmid_term_tfidf[e.pmid, e.term, e.tfidf]\n",
    "    \n",
    "    e.act_prob[e.voxid, e.prob] = (\n",
    "        e.act_counts[e.voxid, e.count] &\n",
    "        e.quantity_docs[e.q] &\n",
    "        (e.prob == e.count / e.q)\n",
    "    )\n",
    "    \n",
    "    nl_results = nl.solve_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = nl_results['julich_voxels'].as_numpy_array()\n",
    "f = [(int(voxid), x, y, z) for voxid, x, y, z in t]\n",
    "julich_voxels = nl.add_tuple_set(tuple(f), name='julich_voxels');\n",
    "\n",
    "t = nl_results['term_docs'].as_numpy_array()\n",
    "f = [(term, pmid) for term, pmid in t]\n",
    "term_docs = nl.add_tuple_set(tuple(f), name='term_docs');\n",
    "\n",
    "t = nl_results['act_counts'].as_numpy_array()\n",
    "f = [(int(voxid), count) for voxid, count in t]\n",
    "act_counts = nl.add_tuple_set(tuple(f), name='act_counts');\n",
    "\n",
    "t = nl_results['act_prob'].as_numpy_array()\n",
    "f = [(int(voxid), p) for voxid, p in t]\n",
    "act_prob = nl.add_tuple_set(tuple(f), name='act_prob');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/Projects/INRIA/NeuroLang/neurolang/datalog/aggregation.py:152: UserWarning: No check performed. Should implement check for stratified aggregation\n",
      "  \"No check performed. Should implement check for stratified\"\n"
     ]
    }
   ],
   "source": [
    "with nl.scope as e:\n",
    "    \n",
    "    e.act_term_counts[e.voxid, e.term, agg_count(e.pmid)] = (\n",
    "        julich_voxels[e.voxid, e.x, e.y, e.z] &\n",
    "        term_docs[e.term, e.pmid] &\n",
    "        e.ns_activations_by_id[e.pmid, e.voxid]\n",
    "    )\n",
    "\n",
    "    e.p_term_given_act[e.term, e.voxid, e.prob] = (\n",
    "        e.act_term_counts[e.voxid, e.term, e.act_term_count] &\n",
    "        act_counts[e.voxid, e.act_count] &\n",
    "        (e.prob == e.act_term_count / e.act_count)\n",
    "    )\n",
    "    \n",
    "    e.e_term_given_aud_act[e.term, agg_sum(e.p)] = (\n",
    "        e.p_term_given_act[e.term, e.voxid, e.prob] & \n",
    "        act_prob[e.voxid, e.act_prob_] &\n",
    "        (e.p == e.prob * e.act_prob_)    \n",
    "    )\n",
    "    \n",
    "    nl_results = nl.solve_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = nl_results['e_term_given_aud_act']._container.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c[1].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>temporal</td>\n",
       "      <td>0.068645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>magnetic</td>\n",
       "      <td>0.059713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>resonance</td>\n",
       "      <td>0.059262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>magnetic resonance</td>\n",
       "      <td>0.059026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>functional magnetic</td>\n",
       "      <td>0.056872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082</th>\n",
       "      <td>using</td>\n",
       "      <td>0.054263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>task</td>\n",
       "      <td>0.050347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>gyrus</td>\n",
       "      <td>0.049727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>frontal</td>\n",
       "      <td>0.048264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>superior</td>\n",
       "      <td>0.047945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>suggest</td>\n",
       "      <td>0.042850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>auditory</td>\n",
       "      <td>0.040106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>network</td>\n",
       "      <td>0.039423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>anterior</td>\n",
       "      <td>0.038770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>superior temporal</td>\n",
       "      <td>0.038031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>inferior</td>\n",
       "      <td>0.037489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>posterior</td>\n",
       "      <td>0.034412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>control</td>\n",
       "      <td>0.034026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>stimuli</td>\n",
       "      <td>0.033950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>response</td>\n",
       "      <td>0.033685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>involved</td>\n",
       "      <td>0.033318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>parietal</td>\n",
       "      <td>0.032976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258</th>\n",
       "      <td>prefrontal</td>\n",
       "      <td>0.032358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>healthy</td>\n",
       "      <td>0.032320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>responses</td>\n",
       "      <td>0.029995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>visual</td>\n",
       "      <td>0.029216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>cingulate</td>\n",
       "      <td>0.028781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>cognitive</td>\n",
       "      <td>0.028286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>information</td>\n",
       "      <td>0.027182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>cortical</td>\n",
       "      <td>0.027114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>motor</td>\n",
       "      <td>0.026865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>level</td>\n",
       "      <td>0.026117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>role</td>\n",
       "      <td>0.025358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1\n",
       "2941             temporal  0.068645\n",
       "1692             magnetic  0.059713\n",
       "2504            resonance  0.059262\n",
       "1693   magnetic resonance  0.059026\n",
       "1217  functional magnetic  0.056872\n",
       "3082                using  0.054263\n",
       "2921                 task  0.050347\n",
       "1290                gyrus  0.049727\n",
       "1192              frontal  0.048264\n",
       "2876             superior  0.047945\n",
       "2865              suggest  0.042850\n",
       "272              auditory  0.040106\n",
       "1925              network  0.039423\n",
       "195              anterior  0.038770\n",
       "2881    superior temporal  0.038031\n",
       "1466             inferior  0.037489\n",
       "2215            posterior  0.034412\n",
       "593               control  0.034026\n",
       "2800              stimuli  0.033950\n",
       "2520             response  0.033685\n",
       "1554             involved  0.033318\n",
       "2084             parietal  0.032976\n",
       "2258           prefrontal  0.032358\n",
       "1317              healthy  0.032320\n",
       "2525            responses  0.029995\n",
       "3144               visual  0.029216\n",
       "422             cingulate  0.028781\n",
       "449             cognitive  0.028286\n",
       "1478          information  0.027182\n",
       "670              cortical  0.027114\n",
       "1863                motor  0.026865\n",
       "1631                level  0.026117\n",
       "2560                 role  0.025358"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[c[1] >= c[1].quantile(.99)].sort_values(1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>temporal</td>\n",
       "      <td>0.068645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>magnetic</td>\n",
       "      <td>0.059713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>resonance</td>\n",
       "      <td>0.059262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>magnetic resonance</td>\n",
       "      <td>0.059026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>functional magnetic</td>\n",
       "      <td>0.056872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082</th>\n",
       "      <td>using</td>\n",
       "      <td>0.054263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>task</td>\n",
       "      <td>0.050347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>gyrus</td>\n",
       "      <td>0.049727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>frontal</td>\n",
       "      <td>0.048264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>superior</td>\n",
       "      <td>0.047945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>suggest</td>\n",
       "      <td>0.042850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>auditory</td>\n",
       "      <td>0.040106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>network</td>\n",
       "      <td>0.039423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>anterior</td>\n",
       "      <td>0.038770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>superior temporal</td>\n",
       "      <td>0.038031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     term      prob\n",
       "2941             temporal  0.068645\n",
       "1692             magnetic  0.059713\n",
       "2504            resonance  0.059262\n",
       "1693   magnetic resonance  0.059026\n",
       "1217  functional magnetic  0.056872\n",
       "3082                using  0.054263\n",
       "2921                 task  0.050347\n",
       "1290                gyrus  0.049727\n",
       "1192              frontal  0.048264\n",
       "2876             superior  0.047945\n",
       "2865              suggest  0.042850\n",
       "272              auditory  0.040106\n",
       "1925              network  0.039423\n",
       "195              anterior  0.038770\n",
       "2881    superior temporal  0.038031"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = c[c[1] >= c[1].quantile(.99)].sort_values(1, ascending=False)\n",
    "tt.rename(columns={0: 'term', 1: 'prob'}, inplace=True)\n",
    "tt.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse inference - Example using ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/nilearn/plotting/cm.py:159: MatplotlibDeprecationWarning: \n",
      "The revcmap function was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use Colormap.reversed() instead.\n",
      "  _cmaps_data[_cmapname_r] = _cm.revcmap(_cmapspec)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/tatsu/grammars.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import defaultdict, Mapping\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/problog/util.py:250: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  class OrderedSet(collections.MutableSet):\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:435: ResourceWarning: unclosed file <_io.BufferedReader name='/Users/gzanitti/Projects/INRIA/NeuroLang/neurolang/frontend/neurosynth_data/dataset.pkl'>\n",
      "  dataset = pickle.load(open(filename, 'rb'))\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:771: FutureWarning: DataFrame.to_sparse is deprecated and will be removed in a future version\n",
      "  columns=self.data['columns']).to_sparse()\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import stats_helper, datasets_helper\n",
    "from neurolang.frontend.probabilistic_frontend import ProbabilisticFrontend\n",
    "from rdflib import RDFS, RDF\n",
    "from nilearn import plotting\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Iterable\n",
    "from neurolang import frontend as fe\n",
    "\n",
    "nl = fe.probabilistic_frontend.ProbabilisticFrontend()\n",
    "\n",
    "datasets_helper.load_reverse_inference_dataset_deterministic(nl)\n",
    "\n",
    "paths = 'neurolang_data/ontologies/cogat.xrdf'\n",
    "nl.load_ontology(paths)\n",
    "\n",
    "\n",
    "@nl.add_symbol\n",
    "def agg_count(x: Iterable) -> int:\n",
    "    return len(x)\n",
    "\n",
    "@nl.add_symbol\n",
    "def agg_sum(x: Iterable) -> float:\n",
    "    return x.sum()\n",
    "\n",
    "@nl.add_symbol\n",
    "def agg_mean(x: Iterable) -> float:\n",
    "    return x.mean()\n",
    "\n",
    "@nl.add_symbol\n",
    "def first_word(name: str) -> str:\n",
    "    return name.split(\" \")[0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_of = nl.new_symbol(name='http://www.obofoundry.org/ro/ro.owl#part_of')\n",
    "subclass_of = nl.new_symbol(name=str(RDFS.subClassOf))\n",
    "label = nl.new_symbol(name=str(RDFS.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#triples = nl.symbol_table[nl.get_ontology_triples_symbol().name]\n",
    "#a = triples.value.as_numpy_array()\n",
    "#t = [('Auditory', str(RDF.type), 'http://www.cognitiveatlas.org/ontology/cogat.owl#CAO_00148')]\n",
    "\n",
    "#t = np.concatenate((a, t))\n",
    "#nl.add_extensional_predicate_from_tuples(t, name=nl.get_ontology_triples_symbol().name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/Projects/INRIA/NeuroLang/neurolang/datalog/aggregation.py:152: UserWarning: No check performed. Should implement check for stratified aggregation\n",
      "  \"No check performed. Should implement check for stratified\"\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:4218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:4218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:4218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:4218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "with nl.scope as e:\n",
    "    e.julich_to_neurosynth[e.julich_id, e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.xyz_julich[e.x, e.y, e.z, e.julich_id] &\n",
    "        e.xyz_neurosynth[e.x, e.y, e.z, e.id_neurosynth]\n",
    "    )\n",
    "    \n",
    "    e.region_voxels[e.name, e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.julich_id[e.name, e.julich_id] &\n",
    "        e.julich_to_neurosynth[e.julich_id, e.id_neurosynth, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    e.julich_id[e.name, e.id] = (\n",
    "        e.julich_ontology[e.name, 'labelIndex', e.id]\n",
    "    )\n",
    "    \n",
    "    #e.julich_id[e.name, e.id] = (\n",
    "    #    e.julich_ontology[e.name, 'subClassOf', e.son_name] &\n",
    "    #    e.julich_id[e.son_name, e.id]\n",
    "    #)\n",
    "    \n",
    "    e.julich_voxels[e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.region_voxels['Area TE 3 (STG)', e.id_neurosynth, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    e.term_docs[e.term, e.pmid] = (\n",
    "        e.ns_pmid_term_tfidf[e.pmid, e.term, e.tfidf] &\n",
    "        (e.tfidf > 1e-3)        \n",
    "    )\n",
    "\n",
    "    e.term_counts[e.term, agg_count(e.pmid)] =  (\n",
    "        e.ns_pmid_term_tfidf[e.pmid, e.term, e.tfidf] &\n",
    "        e.term_docs[e.term, e.pmid]\n",
    "    )\n",
    "    \n",
    "    e.act_counts[e.voxid, agg_count(e.pmid)] = e.ns_activations_by_id[e.pmid, e.voxid]\n",
    "    \n",
    "    e.quantity_docs[agg_count(e.pmid)] = e.ns_pmid_term_tfidf[e.pmid, e.term, e.tfidf]\n",
    "    \n",
    "    e.act_prob[e.voxid, e.prob] = (\n",
    "        e.act_counts[e.voxid, e.count] &\n",
    "        e.quantity_docs[e.q] &\n",
    "        (e.prob == e.count / e.q)\n",
    "    )\n",
    "    \n",
    "    nl_results = nl.solve_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = nl_results['julich_voxels'].as_numpy_array()\n",
    "f = [(int(voxid), x, y, z) for voxid, x, y, z in t]\n",
    "julich_voxels = nl.add_tuple_set(tuple(f), name='julich_voxels');\n",
    "\n",
    "t = nl_results['term_docs'].as_numpy_array()\n",
    "f = [(term, pmid) for term, pmid in t]\n",
    "term_docs = nl.add_tuple_set(tuple(f), name='term_docs');\n",
    "\n",
    "t = nl_results['act_counts'].as_numpy_array()\n",
    "f = [(int(voxid), count) for voxid, count in t]\n",
    "act_counts = nl.add_tuple_set(tuple(f), name='act_counts');\n",
    "\n",
    "t = nl_results['act_prob'].as_numpy_array()\n",
    "f = [(int(voxid), p) for voxid, p in t]\n",
    "act_prob = nl.add_tuple_set(tuple(f), name='act_prob');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurolang.expressions import Constant, Symbol\n",
    "\n",
    "@nl.add_symbol\n",
    "def words(x: Iterable) -> str:\n",
    "    b = ''\n",
    "    for a in x:\n",
    "        b = b + a + ' '\n",
    "        \n",
    "    b = set(b.lower().split(' '))\n",
    "    \n",
    "    return \" \".join(b)\n",
    "\n",
    "@nl.add_symbol\n",
    "def is_in(x: str, l: str) -> str:\n",
    "    b = l.split(' ')\n",
    "    if x in b:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/Projects/INRIA/NeuroLang/neurolang/datalog/aggregation.py:152: UserWarning: No check performed. Should implement check for stratified aggregation\n",
      "  \"No check performed. Should implement check for stratified\"\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:4218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:4218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:4218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:4218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "hasTopConcept = nl.new_symbol(name='http://www.w3.org/2004/02/skos/core#hasTopConcept')\n",
    "with nl.scope as e:\n",
    "    #e.pre_part[e.x, e.y] = part_of[e.x, e.y]\n",
    "\n",
    "    e.ontology_terms[e.name] = (\n",
    "        hasTopConcept[e.uri, 'Perception'] &\n",
    "        label[e.uri, e.name]\n",
    "    )\n",
    "    \n",
    "    e.act_term_counts[e.voxid, e.term, agg_count(e.pmid)] = (\n",
    "        julich_voxels[e.voxid, e.x, e.y, e.z] &\n",
    "        term_docs[e.term, e.pmid] &\n",
    "        e.ns_activations_by_id[e.pmid, e.voxid]\n",
    "    )\n",
    "\n",
    "    e.p_term_given_act[e.term, e.voxid, e.prob] = (\n",
    "        e.act_term_counts[e.voxid, e.term, e.act_term_count] &\n",
    "        act_counts[e.voxid, e.act_count] &\n",
    "        (e.prob == e.act_term_count / e.act_count)\n",
    "    )\n",
    "    \n",
    "    e.e_term_given_aud_act[e.term, agg_sum(e.p)] = (\n",
    "        e.p_term_given_act[e.term, e.voxid, e.prob] & \n",
    "        act_prob[e.voxid, e.act_prob_] &\n",
    "        (e.p == e.prob * e.act_prob_)    \n",
    "    )\n",
    "    \n",
    "    nl_results = nl.solve_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = nl_results['ontology_terms'].as_numpy_array()\n",
    "f = [tuple(term)[0].lower() for term in t]\n",
    "julich_voxels = nl.add_tuple_set(tuple(f), name='ontology_terms');\n",
    "\n",
    "t = nl_results['e_term_given_aud_act'].as_numpy_array()\n",
    "f = [(term, p) for term, p in t]\n",
    "julich_voxels = nl.add_tuple_set(tuple(f), name='reverse_inference');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nl.scope as e:\n",
    "    e.filtered_terms[e.term, e.p] = (\n",
    "        e.ontology_terms[e.term] & \n",
    "        e.reverse_inference[e.term, e.p]\n",
    "    )\n",
    "    \n",
    "    nl_results = nl.solve_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>perception</td>\n",
       "      <td>0.020117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>detection</td>\n",
       "      <td>0.006216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>discrimination</td>\n",
       "      <td>0.004777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>localization</td>\n",
       "      <td>0.002494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>multisensory</td>\n",
       "      <td>0.002336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rhythm</td>\n",
       "      <td>0.001838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mental imagery</td>\n",
       "      <td>0.000991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>visual perception</td>\n",
       "      <td>0.000980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>navigation</td>\n",
       "      <td>0.000619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>object recognition</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 term      prob\n",
       "7          perception  0.020117\n",
       "1           detection  0.006216\n",
       "3      discrimination  0.004777\n",
       "5        localization  0.002494\n",
       "8        multisensory  0.002336\n",
       "4              rhythm  0.001838\n",
       "2      mental imagery  0.000991\n",
       "9   visual perception  0.000980\n",
       "6          navigation  0.000619\n",
       "0  object recognition  0.000242"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = nl_results['filtered_terms']._container.copy()\n",
    "tt = c.sort_values(1, ascending=False)\n",
    "tt.rename(columns={0: 'term', 1: 'prob'}, inplace=True)\n",
    "tt.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[1].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[c[1] >= c[1].quantile(.99)].sort_values(1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "\n",
    "g = rdflib.Graph()\n",
    "g.load('neurolang_data/ontologies/cogat.xrdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working memory maintenance\n",
      "Task set\n",
      "Performance monitoring\n",
      "Goal maintenance\n",
      "Task switching\n",
      "Inhibition of return\n",
      "Inhibition\n",
      "Chunking\n",
      "Top down processing\n",
      "Metamemory\n",
      "Visuospatial sketch pad\n",
      "Interference resolution\n",
      "Resource limit\n",
      "Active maintenance\n",
      "Cognitive load\n",
      "Self monitoring\n",
      "Central executive\n",
      "Goal management\n",
      "Maintenance\n",
      "Working memory retrieval\n",
      "Response conflict\n",
      "Updating\n",
      "Monitoring\n",
      "Planning\n",
      "Phonological working memory\n",
      "Goal formation\n",
      "Working memory storage\n",
      "Self control\n",
      "Working memory\n",
      "Resistance to distractor inference\n",
      "Behavioral inhibition (cognitive)\n",
      "Goal\n",
      "Error detection\n",
      "Proactive control\n",
      "Manipulation\n",
      "Selective control\n",
      "Cognitive control\n",
      "Semantic working memory\n",
      "Goal state\n",
      "Supervisory attentional system\n",
      "Response inhibition\n",
      "Set shifting\n"
     ]
    }
   ],
   "source": [
    "control = g.triples((None, rdflib.term.URIRef('http://www.w3.org/2004/02/skos/core#hasTopConcept'), rdflib.term.Literal('Executive-Cognitive Control')))\n",
    "for a, b, c in control:\n",
    "    n = list(g.triples((a, rdflib.term.URIRef('http://www.w3.org/2000/01/rdf-schema#label'), None)))\n",
    "    print(n[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "topCon = set()\n",
    "for a in g.triples((None, rdflib.term.URIRef('http://www.w3.org/2004/02/skos/core#hasTopConcept'), None)):\n",
    "    topCon.add(a[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{rdflib.term.Literal(''),\n",
       " rdflib.term.Literal('Action'),\n",
       " rdflib.term.Literal('Attention'),\n",
       " rdflib.term.Literal('Emotion'),\n",
       " rdflib.term.Literal('Executive-Cognitive Control'),\n",
       " rdflib.term.Literal('Language'),\n",
       " rdflib.term.Literal('Learning and Memory'),\n",
       " rdflib.term.Literal('Motivation'),\n",
       " rdflib.term.Literal('Perception'),\n",
       " rdflib.term.Literal('Reasoning and Decision Making'),\n",
       " rdflib.term.Literal('Social Function')}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topCon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "neurolang",
   "language": "python",
   "name": "neurolang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
