{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/nilearn/plotting/cm.py:159: MatplotlibDeprecationWarning: \n",
      "The revcmap function was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use Colormap.reversed() instead.\n",
      "  _cmaps_data[_cmapname_r] = _cm.revcmap(_cmapspec)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/tatsu/grammars.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import defaultdict, Mapping\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/problog/util.py:250: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  class OrderedSet(collections.MutableSet):\n"
     ]
    }
   ],
   "source": [
    "import stats_helper, datasets_helper\n",
    "from neurolang.frontend.probabilistic_frontend import ProbabilisticFrontend\n",
    "from rdflib import RDFS\n",
    "from nilearn import plotting\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Iterable\n",
    "from neurolang import frontend as fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the FMA ontology to obtain regions of the brain included within the `Temporal lobe`. We will obtain all the entities that make up the `Temporal Lobe` and then we will convert them into regions using the information provided by the Destrieux atlas. This will allow us to perform spatial operations on these regions, allowing us to obtain those NeuroSynth regions associated with the term `auditory` that overlap our results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/mask.py:232: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  return self.volume.get_header()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:624: FutureWarning: DataFrame/Series.to_dense is deprecated and will be removed in a future version\n",
      "  old_data = self.data.to_dense()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:634: FutureWarning: DataFrame.to_sparse is deprecated and will be removed in a future version\n",
      "  self.data = data.fillna(0.0).to_sparse()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:3451: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  return klass(values, index=self.index, name=items, fastpath=True)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:450: ResourceWarning: unclosed file <_io.BufferedWriter name='neurolang_data/neurosynth/dataset.pkl'>\n",
      "  pickle.dump(self, open(filename, 'wb'), -1)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:771: FutureWarning: DataFrame.to_sparse is deprecated and will be removed in a future version\n",
      "  columns=self.data['columns']).to_sparse()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/mask.py:232: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  return self.volume.get_header()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:624: FutureWarning: DataFrame/Series.to_dense is deprecated and will be removed in a future version\n",
      "  old_data = self.data.to_dense()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:634: FutureWarning: DataFrame.to_sparse is deprecated and will be removed in a future version\n",
      "  self.data = data.fillna(0.0).to_sparse()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:3451: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  return klass(values, index=self.index, name=items, fastpath=True)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:450: ResourceWarning: unclosed file <_io.BufferedWriter name='neurolang_data/neurosynth/dataset.pkl'>\n",
      "  pickle.dump(self, open(filename, 'wb'), -1)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:771: FutureWarning: DataFrame.to_sparse is deprecated and will be removed in a future version\n",
      "  columns=self.data['columns']).to_sparse()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/numpy/lib/npyio.py:2358: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  output = genfromtxt(fname, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nl = ProbabilisticFrontend()\n",
    "datasets_helper.load_reverse_inference_dataset(nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'neurolang_data/ontologies/cogat.xrdf'\n",
    "#nl.load_ontology(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/Projects/INRIA/NeuroLang/neurolang/datalog/aggregation.py:152: UserWarning: No check performed. Should implement check for stratified aggregation\n",
      "  \"No check performed. Should implement check for stratified\"\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:4218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on float64 and object columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c6ad8a9cec7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     )\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mnl_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability_voxel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/frontend/probabilistic_frontend.py\u001b[0m in \u001b[0;36msolve_query\u001b[0;34m(self, query_pred)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         deterministic_solution = self.chase_class(\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         ).build_chase_solution()\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprobabilistic_idb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformulas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/datalog/chase/general.py\u001b[0m in \u001b[0;36mbuild_chase_solution\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    500\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mlog_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Evaluating rule %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m                     instance_update = self.per_rule_update(\n\u001b[0;32m--> 502\u001b[0;31m                         \u001b[0mrule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m                     )\n\u001b[1;32m    504\u001b[0m                 \u001b[0mcontinue_chase\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_update\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/datalog/chase/general.py\u001b[0m in \u001b[0;36mper_rule_update\u001b[0;34m(self, rule, instance, instance_update)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mper_rule_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         new_instance_update = self.chase_step(\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestriction_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstance_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         )\n\u001b[1;32m    512\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_instance_update\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/datalog/chase/relational_algebra.py\u001b[0m in \u001b[0;36mchase_step\u001b[0;34m(self, instance, rule, restriction_instance)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         substitutions = self.obtain_substitutions(\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mpredicates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestriction_instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         )\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/datalog/chase/relational_algebra.py\u001b[0m in \u001b[0;36mobtain_substitutions\u001b[0;34m(self, rule_predicates_iterator, instance, restriction_instance)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mLOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'About to execute RA query %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mra_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRelationalAlgebraSolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mra_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mresult_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/expression_walker.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/expression_pattern_matching.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mLOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t\\tpattern: %(pattern)s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'pattern'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mLOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t\\tguard: %(guard)s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'guard'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0mresult_expression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m                 LOG.info(\n\u001b[1;32m    299\u001b[0m                     \u001b[0;34m'\\t\\tresult: %(result_expression)s'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/expression_walker.py\u001b[0m in \u001b[0;36mprocess_expression\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchanged\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mnew_expression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_expression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/expression_walker.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/expression_pattern_matching.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mLOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t\\tpattern: %(pattern)s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'pattern'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mLOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t\\tguard: %(guard)s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'guard'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0mresult_expression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m                 LOG.info(\n\u001b[1;32m    299\u001b[0m                     \u001b[0;34m'\\t\\tresult: %(result_expression)s'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/relational_algebra.py\u001b[0m in \u001b[0;36mra_naturaljoin\u001b[0;34m(self, naturaljoin)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaturaljoin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelation_left\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaturaljoin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelation_right\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaturaljoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_relation_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/INRIA/NeuroLang/neurolang/utils/relational_algebra_set/pandas.py\u001b[0m in \u001b[0;36mnaturaljoin\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mnew_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         return self._light_init_same_structure(\n\u001b[1;32m    498\u001b[0m             \u001b[0mnew_container\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   7321\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7322\u001b[0m             \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7323\u001b[0;31m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7324\u001b[0m         )\n\u001b[1;32m   7325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     )\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# to avoid incompat dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;31m# If argument passed to validate,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1137\u001b[0m                     \u001b[0minferred_right\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_types\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minferred_left\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 ):\n\u001b[0;32m-> 1139\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0;31m# datetimelikes must match exactly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on float64 and object columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "with nl.scope as e:\n",
    "    e.julich_to_neurosynth[e.julich_id, e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.xyz_julich[e.x, e.y, e.z, e.julich_id] &\n",
    "        e.xyz_neurosynth[e.x, e.y, e.z, e.id_neurosynth] \n",
    "    )\n",
    "    \n",
    "    e.region_voxels[e.name, e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.julich_id[e.name, e.julich_id] &\n",
    "        e.julich_to_neurosynth[e.julich_id, e.id_neurosynth, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    e.julich_id[e.name, e.id] = (\n",
    "        e.julich_ontology[e.name, 'labelIndex', e.id]\n",
    "    )\n",
    "    \n",
    "    e.julich_voxels[e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.region_voxels['Area TE 3 (STG)', e.id_neurosynth, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    e.p_act[e.id_voxel, e.term] = (\n",
    "        e.p_voxel_study[e.id_voxel, e.id_study] & \n",
    "        e.p_term_study[e.term,  e.id_study] & \n",
    "        e.p_study[e.id_study]\n",
    "    )\n",
    "    \n",
    "    e.probability_voxel[e.term] = (\n",
    "        e.p_act[e.id_voxel, e.term] &\n",
    "        e.julich_voxels[e.id_voxel, e.x, e.y, e.z]&\n",
    "        e.prob_julich[e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    nl_results = nl.solve_query(e.probability_voxel[e.term])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>fresh_00004571</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>8.259320e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>8.654360e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05</td>\n",
       "      <td>1.696883e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>3.720645e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>1.569163e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  term  fresh_00004571\n",
       "0  001    8.259320e-08\n",
       "1   01    8.654360e-08\n",
       "2   05    1.696883e-07\n",
       "3   10    3.720645e-07\n",
       "4  100    1.569163e-07"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl_results.value.as_pandas_dataframe().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:624: FutureWarning: DataFrame/Series.to_dense is deprecated and will be removed in a future version\n",
      "  old_data = self.data.to_dense()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:634: FutureWarning: DataFrame.to_sparse is deprecated and will be removed in a future version\n",
      "  self.data = data.fillna(0.0).to_sparse()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/mask.py:232: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  return self.volume.get_header()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:624: FutureWarning: DataFrame/Series.to_dense is deprecated and will be removed in a future version\n",
      "  old_data = self.data.to_dense()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:634: FutureWarning: DataFrame.to_sparse is deprecated and will be removed in a future version\n",
      "  self.data = data.fillna(0.0).to_sparse()\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/numpy/lib/npyio.py:2358: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  output = genfromtxt(fname, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import stats_helper, datasets_helper\n",
    "from neurolang.frontend.probabilistic_frontend import ProbabilisticFrontend\n",
    "from rdflib import RDFS\n",
    "from nilearn import plotting\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Iterable\n",
    "from neurolang import frontend as fe\n",
    "\n",
    "nl = ProbabilisticFrontend()\n",
    "datasets_helper.load_reverse_inference_dataset(nl)\n",
    "\n",
    "path = 'neurolang_data/ontologies/cogat.xrdf'\n",
    "nl.load_ontology(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_of = nl.new_symbol(name='http://www.obofoundry.org/ro/ro.owl#part_of')\n",
    "subclass_of = nl.new_symbol(name=str(RDFS.subClassOf))\n",
    "label = nl.new_symbol(name=str(RDFS.label))\n",
    "hasTopConcept = nl.new_symbol(name='http://www.w3.org/2004/02/skos/core#hasTopConcept')\n",
    "\n",
    "@nl.add_symbol\n",
    "def word_lower(name1: str, name2: str) -> bool:\n",
    "    print('-->', name1, name2)\n",
    "    if str(name1).lower() == str(name2).lower():\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/Projects/INRIA/NeuroLang/neurolang/datalog/aggregation.py:152: UserWarning: No check performed. Should implement check for stratified aggregation\n",
      "  \"No check performed. Should implement check for stratified\"\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:4218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from operator import eq\n",
    "\n",
    "with nl.scope as e:\n",
    "    e.julich_to_neurosynth[e.julich_id, e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.xyz_julich[e.x, e.y, e.z, e.julich_id] &\n",
    "        e.xyz_neurosynth[e.x, e.y, e.z, e.id_neurosynth]\n",
    "    )\n",
    "    \n",
    "    e.region_voxels[e.name, e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.julich_id[e.name, e.julich_id] &\n",
    "        e.julich_to_neurosynth[e.julich_id, e.id_neurosynth, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    e.julich_id[e.name, e.id] = (\n",
    "        e.julich_ontology[e.name, 'labelIndex', e.id]\n",
    "    )\n",
    "    \n",
    "    e.julich_voxels[e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.region_voxels['Area TE 3 (STG)', e.id_neurosynth, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    e.p_act[e.id_voxel, e.term] = (\n",
    "        e.p_voxel_study[e.id_voxel, e.id_study] & \n",
    "        e.p_term_study[e.term,  e.id_study] & \n",
    "        e.p_study[e.id_study]\n",
    "    )\n",
    "    \n",
    "    e.ontology_terms[e.name] = (\n",
    "        hasTopConcept[e.uri, 'Perception'] &\n",
    "        label[e.uri, e.name]\n",
    "    )\n",
    "    \n",
    "    #e.probability_voxel[e.term1] = (\n",
    "    #    e.p_act[e.id_voxel, e.term1] &\n",
    "    #    e.julich_voxels[e.id_voxel, e.x, e.y, e.z] &\n",
    "    #    e.ontology_terms[e.term2] &\n",
    "    #    word_lower[e.term1, e.term2]\n",
    "    #)\n",
    "    \n",
    "    nl_results = nl.solve_query(e.p_act[e.id_voxel, e.term])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = nl.new_symbol(name=str(RDFS.label))\n",
    "subclass_of = nl.new_symbol(name=str(RDFS.subClassOf))\n",
    "regional_part = nl.new_symbol(name='http://sig.biostr.washington.edu/fma3.0#regional_part_of')\n",
    "\n",
    "#@nl.add_symbol\n",
    "#def agg_create_region(x: Iterable, y: Iterable, z: Iterable) -> fe.ExplicitVBR:\n",
    "#    mni_t1 = it.masker.volume\n",
    "#    voxels = nib.affines.apply_affine(np.linalg.inv(mni_t1.affine), np.c_[x, y, z])\n",
    "#    return fe.ExplicitVBR(voxels, mni_t1.affine, image_dim=mni_t1.shape)\n",
    "\n",
    "@nl.add_symbol\n",
    "def first_word(name: str) -> str:\n",
    "    return name.split(\" \")[0]\n",
    "\n",
    "with nl.environment as e:    \n",
    "    e.fma_related_region[e.subregion_name, e.fma_uri] = (\n",
    "        label(e.xfma_entity_name, e.fma_uri) & \n",
    "        regional_part(e.fma_region, e.xfma_entity_name) & \n",
    "        subclass_of(e.fma_subregion, e.fma_region) &\n",
    "        label(e.fma_subregion, e.subregion_name)\n",
    "    )\n",
    "    e.fma_related_region[e.recursive_region, e.fma_name] = (\n",
    "        subclass_of(e.recursive_region, e.fma_subregion) & e.fma_related_region(e.fma_subregion, e.fma_name)\n",
    "    )\n",
    "    e.fma_to_destrieux[e.fma_name, e.destrieux_name] = (\n",
    "        label(e.fma_uri, e.fma_name) & e.relation_destrieux_fma(e.destrieux_name, e.fma_name)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/Projects/INRIA/NeuroLang/neurolang/datalog/aggregation.py:146: UserWarning: No check performed. Should implement check for stratified aggregation\n",
      "  \"No check performed. Should implement check for stratified\"\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:4218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "with nl.environment as e:\n",
    "    e.region_voxels[e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.fma_related_region[e.fma_subregions, 'Temporal lobe'] & \n",
    "        e.fma_to_destrieux[e.fma_subregions, e.destrieux_name] & \n",
    "        e.destrieux_to_neurosynth[e.destrieux_name, e.id_neurosynth, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    e.destrieux_to_neurosynth[e.destrieux_name, e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.destrieux_labels[e.id_destrieux, e.destrieux_name] &\n",
    "        e.xyz_destrieux[e.x, e.y, e.z, e.id_destrieux] &\n",
    "        e.xyz_neurosynth[e.x, e.y, e.z, e.id_neurosynth]\n",
    "    )\n",
    "    \n",
    "    e.p_act[e.id_voxel, e.term, e.id_study] = (\n",
    "        e.p_voxel_study[e.id_voxel, e.id_study] & \n",
    "        e.p_term_study[e.term,  e.id_study] & \n",
    "        e.p_study[e.id_study]\n",
    "    )\n",
    "    \n",
    "    e.probability_voxel[e.id_voxel, e.x, e.y, e.z] = (\n",
    "        e.p_act[e.id_voxel, e.term, e.id_study] &\n",
    "        e.region_voxels[e.id_voxel, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    #nl_results = nl.solve_all()\n",
    "    nl_results = nl.solve_query(e.probability_voxel[e.id_voxel, e.x, e.y, e.z])\n",
    "    \n",
    "    #e.probability_voxel[nl.symbols.agg_create_region(e.x, e.y, e.z)] = (\n",
    "    #    e.p_act[e.id_voxel, e.term, e.id_study] &\n",
    "    #    e.region_voxels[e.id_voxel, e.x, e.y, e.z]\n",
    "    #)\n",
    "    \n",
    "    #e.final[e.region] = e.probability_voxel[e.region]\n",
    "    \n",
    "    #nl_results = nl.solve_query(e.final[e.region])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = nl_results.value._container.values\n",
    "f = [(float(prob), id_voxel, x, y, z) for z, id_voxel, x, y, prob in t]\n",
    "p_act_aud = nl.add_probabilistic_facts_from_tuples(tuple(f), name='p_act_aud');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_img_nl = datasets_helper.parse_results(nl_results)\n",
    "plotting.plot_stat_map(\n",
    "    prob_img_nl, \n",
    "    title='Tag \"auditory\" (Neurolang)', \n",
    "    cmap='PuBuGn',\n",
    "    display_mode='x',\n",
    "    cut_coords=np.linspace(-63, 63, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    prob_img_nl, title='Tag \"auditory\" (Neurolang)', \n",
    "    cmap='PuBuGn',\n",
    "    display_mode='y',\n",
    "    cut_coords=np.linspace(-30, 5, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import RDF\n",
    "\n",
    "part_of = nl.new_symbol(name='http://www.obofoundry.org/ro/ro.owl#part_of')\n",
    "\n",
    "# Should found a better to imply this\n",
    "triples = nl.symbol_table[nl.get_ontology_triples_symbol().name]\n",
    "a = triples.value.as_numpy_array()\n",
    "t = [('Auditory', str(RDF.type), 'http://www.cognitiveatlas.org/ontology/cogat.owl#CAO_00148')]\n",
    "\n",
    "t = np.concatenate((a, t))\n",
    "nl.add_extensional_predicate_from_tuples(t, name=nl.get_ontology_triples_symbol().name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nl.scope as e:\n",
    "    e.pre_part[e.x, e.y] = part_of[e.x, e.y]\n",
    "\n",
    "    e.perception_terms[e.short_name] = (\n",
    "        e.pre_part[\"Auditory\", e.y] & \n",
    "        subclass_of[e.z, e.y] & \n",
    "        label(e.z, e.term) &\n",
    "        (e.short_name == nl.symbols.first_word(e.term))\n",
    "    )\n",
    "    \n",
    "    e.p_term_given_act[e.term, e.voxid] = (\n",
    "        e.ns_reported_activations[e.study, e.voxid] &\n",
    "        e.perception_terms[e.term] & \n",
    "        e.ns_term_study_associations[e.study, e.term]\n",
    "    )\n",
    "    \n",
    "    e.p_term_g_aud_voxels[e.term] = (\n",
    "        e.p_term_given_act[e.term, e.voxid] &\n",
    "        e.p_act_aud[e.voxid, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    nl_reverse = nl.solve_query(e.p_term_g_aud_voxels[e.term])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#prob_terms, prob_voxels, prob_terms_voxels = stats_helper.load_neurosynth_database()\n",
    "prob_img = stats_helper.parse_neurolang_result(result, prob_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    prob_img, \n",
    "    title='Tag \"auditory\" (Neurolang)', \n",
    "    cmap='PuBuGn',\n",
    "    display_mode='x',\n",
    "    cut_coords=np.linspace(-63, 63, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    prob_img, title='Tag \"auditory\" (Neurolang)', \n",
    "    cmap='PuBuGn',\n",
    "    display_mode='y',\n",
    "    cut_coords=np.linspace(-30, 5, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the same result obtained directly from the NeuroSynth database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_img_ns = stats_helper.parse_neurosynth_result(prob_terms_voxels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    prob_img_ns, title='Tag \"auditory\" (Neurosynth)', \n",
    "    cmap='PuBu',\n",
    "    display_mode='x',\n",
    "    cut_coords=np.linspace(-63, 63, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    prob_img_ns, title='Tag \"auditory\" (Neurosynth)', \n",
    "    cmap='PuBu',\n",
    "    display_mode='y',\n",
    "    cut_coords=np.linspace(-30, 5, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can analyze the results by plotting the p-values obtained. Let's start with the NeuroLang results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, p_values_corrected, p_value_image = stats_helper.compute_p_values(prob_img, q=1e-25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(-np.log10(res))\n",
    "plt.axvline(-np.log10(p_values_corrected), c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    p_value_image, \n",
    "    title=r'$-\\log_{10} P$ value (Neurolang)', \n",
    "    threshold=-np.log10(p_values_corrected), \n",
    "    cmap='YlOrRd',\n",
    "    display_mode='x',\n",
    "    cut_coords=np.linspace(-63, 63, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    p_value_image, title=r'$-\\log_{10} P$ value (Neurolang)', \n",
    "    threshold=-np.log10(p_values_corrected),\n",
    "    cmap='YlOrRd',\n",
    "    display_mode='y',\n",
    "    cut_coords=np.linspace(-30, 5, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above results, we can see that the regions have a high specificity and that they focus entirely on our area of interest. Reducing the area of work in this way allows us to minimize variance, enabling us to obtain results with greater statistical power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's do the same with the NeuroSynth results to compare. It is important to mention that the techniques used for the calculation of the p-values, make a comparison against the average of the activations. Bearing this in mind, by decreasing the region to be analyzed and focusing it on the activated region, the average of the activations increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, p_values_corrected, p_value_image = stats_helper.compute_p_values(prob_img_ns, q=1e-25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(-np.log10(res))\n",
    "plt.axvline(-np.log10(p_values_corrected), c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    p_value_image, \n",
    "    title=r'$-\\log_{10} P$ value (NeuroSynth)', \n",
    "    threshold=-np.log10(p_values_corrected), \n",
    "    cmap='YlOrRd',\n",
    "    display_mode='x',\n",
    "    cut_coords=np.linspace(-63, 63, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    p_value_image, title=r'$-\\log_{10} P$ value (NeuroSynth)', \n",
    "    threshold=-np.log10(p_values_corrected),\n",
    "    cmap='YlOrRd',\n",
    "    display_mode='y',\n",
    "    cut_coords=np.linspace(-30, 5, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen above how despite using a restrictive threshold for the p-value ($q<10^{25}$, FDR corrected), in the Neurosynth example there are activations considered statistically significant in the motor cortex that should not be present for the `auditory` tag. Using a prior information in NeuroLang, we are able to remove these false positives and obtain a cleaner result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "[1] Yarkoni, T.: Neurosynth core tools v0.3.1, DOI: 10.5281/zenodo.9925 (2014). <br/>\n",
    "[2] Yarkoni, T., Poldrack, R. A., Nichols, T. E., Van Essen, D. C. & Wager, T. D: Large-scale automated synthesis of human functional neuroimaging data. Nat. Methods 8, 665–670, DOI: 10.1038/nmeth.1635 (2011). <br/>\n",
    "[3] News. Journal of Investigative Medicine 58 (8), 929 (Dec2010). https://doi.org/10.2310/JIM.0b013e3182025955, http://jim.bmj.com/content/58/8/929.abstract <br/>\n",
    "[4] Insel, T. R., Landis, S.C., Collins, F.S.: Research priorities. The NIHBRAIN Initiative. Science (New York, N.Y.) 340 (6133), 687–688 (May  2013). https://doi.org/10.1126/science.1239276 <br/>\n",
    "[5] Markram, H.: The human brain project. Scientific American306(6), 50–55 (Jun2012). https://doi.org/10.1038/scientificamerican0612-50\n",
    "[6] Derrfuss, J. & Mar, R. A. Lost in localization: the need for a universal coordinate database. NeuroImage 48, 1–7, DOI:10.1016/j.neuroimage.2009.01.053 (2009)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "neurolang",
   "language": "python",
   "name": "neurolang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
