{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stats_helper, datasets_helper\n",
    "from neurolang.frontend.probabilistic_frontend import ProbabilisticFrontend\n",
    "from rdflib import RDFS\n",
    "from nilearn import plotting\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Iterable\n",
    "from neurolang import frontend as fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the FMA ontology to obtain regions of the brain included within the `Temporal lobe`. We will obtain all the entities that make up the `Temporal Lobe` and then we will convert them into regions using the information provided by the Destrieux atlas. This will allow us to perform spatial operations on these regions, allowing us to obtain those NeuroSynth regions associated with the term `auditory` that overlap our results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl = ProbabilisticFrontend()\n",
    "datasets_helper.load_reverse_inference_dataset(nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C{          x     y     z   j_id\n",
      "0      72.0 -36.0  -2.0   59.0\n",
      "1      72.0 -34.0  -4.0   59.0\n",
      "2      72.0 -34.0  -2.0   59.0\n",
      "3      72.0 -32.0  -4.0   59.0\n",
      "4      72.0 -28.0   6.0   30.0\n",
      "...     ...   ...   ...    ...\n",
      "74602  -4.0  48.0  16.0  115.0\n",
      "74603  -6.0 -42.0  52.0   94.0\n",
      "74604  -6.0 -40.0  54.0   94.0\n",
      "74605  -6.0 -34.0  50.0   94.0\n",
      "74606  -6.0 -26.0  60.0   92.0\n",
      "\n",
      "[74607 rows x 4 columns]: typing.AbstractSet[typing.Tuple[float, float, float, float]]}\n",
      "C{           x     y     z  id_neurosynth\n",
      "0       72.0 -34.0  -2.0              1\n",
      "1       72.0 -34.0   0.0              2\n",
      "2       72.0 -32.0  -4.0              3\n",
      "3       72.0 -32.0  -2.0              4\n",
      "4       72.0 -30.0  -6.0              5\n",
      "...      ...   ...   ...            ...\n",
      "228447 -70.0 -24.0  -8.0         228448\n",
      "228448 -70.0 -22.0 -14.0         228449\n",
      "228449 -70.0 -22.0 -12.0         228450\n",
      "228450 -70.0 -22.0 -10.0         228451\n",
      "228451 -70.0 -20.0 -12.0         228452\n",
      "\n",
      "[228452 rows x 4 columns]: typing.AbstractSet[typing.Tuple[float, float, float, int]]}\n",
      "---\n",
      "C{                                   j_name  j_id\n",
      "0                Ch 123 (Basal Forebrain)    76\n",
      "1                  Ch 4 (Basal Forebrain)    12\n",
      "2                Ch 123 (Basal Forebrain)    76\n",
      "3                           LB (Amygdala)    90\n",
      "4                           CM (Amygdala)    43\n",
      "..                                    ...   ...\n",
      "117       Interposed Nucleus (Cerebellum)   108\n",
      "118   Dorsal Dentate Nucleus (Cerebellum)    17\n",
      "119  Ventral Dentate Nucleus (Cerebellum)    60\n",
      "120        Fastigial Nucleus (Cerebellum)   101\n",
      "121       Interposed Nucleus (Cerebellum)   108\n",
      "\n",
      "[122 rows x 2 columns]: typing.AbstractSet[typing.Tuple[str, int]]}\n",
      "C{        j_id  id_neurosynth     x     y     z\n",
      "0       59.0              1  72.0 -34.0  -2.0\n",
      "1       59.0              3  72.0 -32.0  -4.0\n",
      "2       59.0             10  70.0 -44.0  -4.0\n",
      "3       59.0             11  70.0 -44.0  -2.0\n",
      "4       59.0             12  70.0 -44.0   0.0\n",
      "...      ...            ...   ...   ...   ...\n",
      "73178  115.0         125292  -4.0  48.0  16.0\n",
      "73179   94.0         127288  -6.0 -42.0  52.0\n",
      "73180   94.0         127358  -6.0 -40.0  54.0\n",
      "73181   94.0         127558  -6.0 -34.0  50.0\n",
      "73182   92.0         127826  -6.0 -26.0  60.0\n",
      "\n",
      "[73183 rows x 5 columns]: typing.AbstractSet[typing.Tuple[float, int, float, float, float]]}\n",
      "---\n",
      "C{{}: typing.AbstractSet[typing.Tuple]}\n",
      "C{{}: typing.AbstractSet[typing.Tuple]}\n",
      "---\n",
      "C{{}: typing.AbstractSet[typing.Tuple]}\n",
      "C{{}: typing.AbstractSet[typing.Tuple]}\n",
      "---\n",
      "C{{}: typing.AbstractSet[typing.Tuple]}\n",
      "C{     id_voxel     x     y     z\n",
      "0          61  70.0 -36.0   4.0\n",
      "1          62  70.0 -36.0   6.0\n",
      "2          63  70.0 -36.0   8.0\n",
      "3          64  70.0 -36.0  10.0\n",
      "4          77  70.0 -34.0   2.0\n",
      "..        ...   ...   ...   ...\n",
      "680     14008  52.0  12.0  -6.0\n",
      "681     14052  52.0  14.0  -8.0\n",
      "682     14093  52.0  16.0 -10.0\n",
      "683     14094  52.0  16.0  -8.0\n",
      "684     14133  52.0  18.0 -10.0\n",
      "\n",
      "[685 rows x 4 columns]: typing.AbstractSet[typing.Tuple[int, float, float, float]]}\n",
      "---\n",
      "C{          x     y     z   j_id\n",
      "0      72.0 -36.0  -2.0   59.0\n",
      "1      72.0 -34.0  -4.0   59.0\n",
      "2      72.0 -34.0  -2.0   59.0\n",
      "3      72.0 -32.0  -4.0   59.0\n",
      "4      72.0 -28.0   6.0   30.0\n",
      "...     ...   ...   ...    ...\n",
      "74602  -4.0  48.0  16.0  115.0\n",
      "74603  -6.0 -42.0  52.0   94.0\n",
      "74604  -6.0 -40.0  54.0   94.0\n",
      "74605  -6.0 -34.0  50.0   94.0\n",
      "74606  -6.0 -26.0  60.0   92.0\n",
      "\n",
      "[74607 rows x 4 columns]: typing.AbstractSet[typing.Tuple[float, float, float, float]]}\n",
      "C{           x     y     z  id_neurosynth\n",
      "0       72.0 -34.0  -2.0              1\n",
      "1       72.0 -34.0   0.0              2\n",
      "2       72.0 -32.0  -4.0              3\n",
      "3       72.0 -32.0  -2.0              4\n",
      "4       72.0 -30.0  -6.0              5\n",
      "...      ...   ...   ...            ...\n",
      "228447 -70.0 -24.0  -8.0         228448\n",
      "228448 -70.0 -22.0 -14.0         228449\n",
      "228449 -70.0 -22.0 -12.0         228450\n",
      "228450 -70.0 -22.0 -10.0         228451\n",
      "228451 -70.0 -20.0 -12.0         228452\n",
      "\n",
      "[228452 rows x 4 columns]: typing.AbstractSet[typing.Tuple[float, float, float, int]]}\n",
      "---\n",
      "C{                                   j_name  j_id\n",
      "0                Ch 123 (Basal Forebrain)    76\n",
      "1                  Ch 4 (Basal Forebrain)    12\n",
      "2                Ch 123 (Basal Forebrain)    76\n",
      "3                           LB (Amygdala)    90\n",
      "4                           CM (Amygdala)    43\n",
      "..                                    ...   ...\n",
      "117       Interposed Nucleus (Cerebellum)   108\n",
      "118   Dorsal Dentate Nucleus (Cerebellum)    17\n",
      "119  Ventral Dentate Nucleus (Cerebellum)    60\n",
      "120        Fastigial Nucleus (Cerebellum)   101\n",
      "121       Interposed Nucleus (Cerebellum)   108\n",
      "\n",
      "[122 rows x 2 columns]: typing.AbstractSet[typing.Tuple[str, int]]}\n",
      "C{        j_id  id_neurosynth     x     y     z\n",
      "0       59.0              1  72.0 -34.0  -2.0\n",
      "1       59.0              3  72.0 -32.0  -4.0\n",
      "2       59.0             10  70.0 -44.0  -4.0\n",
      "3       59.0             11  70.0 -44.0  -2.0\n",
      "4       59.0             12  70.0 -44.0   0.0\n",
      "...      ...            ...   ...   ...   ...\n",
      "73178  115.0         125292  -4.0  48.0  16.0\n",
      "73179   94.0         127288  -6.0 -42.0  52.0\n",
      "73180   94.0         127358  -6.0 -40.0  54.0\n",
      "73181   94.0         127558  -6.0 -34.0  50.0\n",
      "73182   92.0         127826  -6.0 -26.0  60.0\n",
      "\n",
      "[73183 rows x 5 columns]: typing.AbstractSet[typing.Tuple[float, int, float, float, float]]}\n",
      "---\n",
      "C{{}: typing.AbstractSet[typing.Tuple]}\n",
      "C{{}: typing.AbstractSet[typing.Tuple]}\n",
      "---\n",
      "C{{}: typing.AbstractSet[typing.Tuple]}\n",
      "C{{}: typing.AbstractSet[typing.Tuple]}\n",
      "---\n",
      "C{{}: typing.AbstractSet[typing.Tuple]}\n",
      "C{     id_voxel     x     y     z\n",
      "0          61  70.0 -36.0   4.0\n",
      "1          62  70.0 -36.0   6.0\n",
      "2          63  70.0 -36.0   8.0\n",
      "3          64  70.0 -36.0  10.0\n",
      "4          77  70.0 -34.0   2.0\n",
      "..        ...   ...   ...   ...\n",
      "680     14008  52.0  12.0  -6.0\n",
      "681     14052  52.0  14.0  -8.0\n",
      "682     14093  52.0  16.0 -10.0\n",
      "683     14094  52.0  16.0  -8.0\n",
      "684     14133  52.0  18.0 -10.0\n",
      "\n",
      "[685 rows x 4 columns]: typing.AbstractSet[typing.Tuple[int, float, float, float]]}\n",
      "---\n",
      "C{            col_0 ns_term  fresh_00000006\n",
      "0        0.055394     001         9862924\n",
      "1        0.093876     001        11595392\n",
      "2        0.068993     001        12077009\n",
      "3        0.099694     001        12725761\n",
      "4        0.091982     001        12880904\n",
      "...           ...     ...             ...\n",
      "1049294  0.124195    zone        27531977\n",
      "1049295  0.080547    zone        28213115\n",
      "1049296  0.384085    zone        28400265\n",
      "1049297  0.093884    zone        29107022\n",
      "1049298  0.100716    zone        29203205\n",
      "\n",
      "[1049299 rows x 3 columns]: typing.AbstractSet[typing.Tuple[float, str, int]]}\n",
      "C{          fresh_00000011  fresh_00000002  fresh_00000006\n",
      "0                0.00007               0        11004124\n",
      "1                0.00007               0        15737663\n",
      "2                0.00007               0        15961322\n",
      "3                0.00007               0        16157283\n",
      "4                0.00007               0        16168731\n",
      "...                  ...             ...             ...\n",
      "45497607         0.00007          228452        27932074\n",
      "45497608         0.00007          228452        28179554\n",
      "45497609         0.00007          228452        28242496\n",
      "45497610         0.00007          228452        28633048\n",
      "45497611         0.00007          228452        29181589\n",
      "\n",
      "[45497612 rows x 3 columns]: typing.AbstractSet[typing.Tuple[float, int, int]]}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "with nl.scope as e:\n",
    "    e.julich_to_neurosynth[e.j_id, e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.xyz_julich[e.x, e.y, e.z, e.j_id] &\n",
    "        e.xyz_neurosynth[e.x, e.y, e.z, e.id_neurosynth] \n",
    "    )\n",
    "    \n",
    "    e.julich_id[e.j_name, e.id] = (\n",
    "        e.julich_ontology[e.j_name, 'labelIndex', e.id]\n",
    "    )\n",
    "    \n",
    "    e.region_voxels[e.j_name, e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.julich_id[e.j_name, e.j_id] &\n",
    "        e.julich_to_neurosynth[e.j_id, e.id_neurosynth, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    e.julich_voxels[e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.region_voxels['Area TE 3 (STG)', e.id_neurosynth, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    e.p_act[e.id_voxel, e.term] = (\n",
    "        e.p_voxel_study[e.id_voxel, e.id_study] & \n",
    "        e.p_term_study[e.term,  e.id_study] & \n",
    "        e.p_study[e.id_study]\n",
    "    )\n",
    "    \n",
    "    e.probability_voxel[e.ns_term] = (\n",
    "        e.p_act[e.id_voxel, e.ns_term] &\n",
    "        e.julich_voxels[e.id_voxel, e.x, e.y, e.z] #&\n",
    "        e.prob_julich[e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    nl_results = nl.solve_query(e.probability_voxel[e.ns_term])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{S{relation_destrieux_fma: typing.AbstractSet[typing.Tuple[str, str]]}:                               0                                           1\n",
       "0        l_g_and_s_frontomargin                   Left frontomarginal gyrus\n",
       "1       l_g_and_s_occipital_inf               Left inferior occipital gyrus\n",
       "2         l_g_and_s_paracentral                     Left paracentral lobule\n",
       "3          l_g_and_s_subcentral                       Left subcentral gyrus\n",
       "4    l_g_and_s_transv_frontopol  Left superior transverse frontopolar gyrus\n",
       "..                          ...                                         ...\n",
       "145              r_s_suborbital                 Right fronto-orbital sulcus\n",
       "146             r_s_subparietal                    Right subparietal sulcus\n",
       "147            r_s_temporal_inf              Right inferior temporal sulcus\n",
       "148            r_s_temporal_sup              Right superior temporal sulcus\n",
       "149     r_s_temporal_transverse            Right transverse temporal sulcus\n",
       "\n",
       "[150 rows x 2 columns], S{xyz_destrieux: typing.AbstractSet[typing.Tuple[float, float, float, int]]}:           0     1    2    3\n",
       "0      72.0 -28.0  2.0  109\n",
       "1      72.0 -28.0  4.0  109\n",
       "2      72.0 -28.0  6.0  109\n",
       "3      72.0 -26.0  4.0  109\n",
       "4      72.0 -24.0  4.0  109\n",
       "...     ...   ...  ...  ...\n",
       "95323 -70.0 -24.0  0.0   34\n",
       "95324 -70.0 -24.0  2.0   34\n",
       "95325 -70.0 -24.0  4.0   34\n",
       "95326 -70.0 -24.0  6.0   34\n",
       "95327 -70.0 -22.0  2.0   34\n",
       "\n",
       "[95328 rows x 4 columns], S{xyz_julich: typing.AbstractSet[typing.Tuple[float, float, float, float]]}:           0     1     2      3\n",
       "0      72.0 -36.0  -2.0   59.0\n",
       "1      72.0 -34.0  -4.0   59.0\n",
       "2      72.0 -34.0  -2.0   59.0\n",
       "3      72.0 -32.0  -4.0   59.0\n",
       "4      72.0 -28.0   6.0   30.0\n",
       "...     ...   ...   ...    ...\n",
       "74602  -4.0  48.0  16.0  115.0\n",
       "74603  -6.0 -42.0  52.0   94.0\n",
       "74604  -6.0 -40.0  54.0   94.0\n",
       "74605  -6.0 -34.0  50.0   94.0\n",
       "74606  -6.0 -26.0  60.0   92.0\n",
       "\n",
       "[74607 rows x 4 columns], S{julich_ontology: typing.AbstractSet[typing.Tuple[str, str, int]]}:                                         0           1    2\n",
       "0                Ch 123 (Basal Forebrain)  labelIndex   76\n",
       "1                  Ch 4 (Basal Forebrain)  labelIndex   12\n",
       "2                Ch 123 (Basal Forebrain)  labelIndex   76\n",
       "3                           LB (Amygdala)  labelIndex   90\n",
       "4                           CM (Amygdala)  labelIndex   43\n",
       "..                                    ...         ...  ...\n",
       "117       Interposed Nucleus (Cerebellum)  labelIndex  108\n",
       "118   Dorsal Dentate Nucleus (Cerebellum)  labelIndex   17\n",
       "119  Ventral Dentate Nucleus (Cerebellum)  labelIndex   60\n",
       "120        Fastigial Nucleus (Cerebellum)  labelIndex  101\n",
       "121       Interposed Nucleus (Cerebellum)  labelIndex  108\n",
       "\n",
       "[122 rows x 3 columns], S{destrieux_labels: typing.AbstractSet[typing.Tuple[int, str]]}:        0                        1\n",
       "0      0               background\n",
       "1      1   l_g_and_s_frontomargin\n",
       "2      2  l_g_and_s_occipital_inf\n",
       "3      3    l_g_and_s_paracentral\n",
       "4      4     l_g_and_s_subcentral\n",
       "..   ...                      ...\n",
       "146  146           r_s_suborbital\n",
       "147  147          r_s_subparietal\n",
       "148  148         r_s_temporal_inf\n",
       "149  149         r_s_temporal_sup\n",
       "150  150  r_s_temporal_transverse\n",
       "\n",
       "[151 rows x 2 columns], S{xyz_neurosynth: typing.AbstractSet[typing.Tuple[float, float, float, int]]}:            0     1     2       3\n",
       "0       72.0 -34.0  -2.0       1\n",
       "1       72.0 -34.0   0.0       2\n",
       "2       72.0 -32.0  -4.0       3\n",
       "3       72.0 -32.0  -2.0       4\n",
       "4       72.0 -30.0  -6.0       5\n",
       "...      ...   ...   ...     ...\n",
       "228447 -70.0 -24.0  -8.0  228448\n",
       "228448 -70.0 -22.0 -14.0  228449\n",
       "228449 -70.0 -22.0 -12.0  228450\n",
       "228450 -70.0 -22.0 -10.0  228451\n",
       "228451 -70.0 -20.0 -12.0  228452\n",
       "\n",
       "[228452 rows x 4 columns], S{julich_to_neurosynth: Unknown}:            0       1     2     3     4\n",
       "0       59.0       1  72.0 -34.0  -2.0\n",
       "1       59.0       3  72.0 -32.0  -4.0\n",
       "2       59.0      10  70.0 -44.0  -4.0\n",
       "3       59.0      11  70.0 -44.0  -2.0\n",
       "4       59.0      12  70.0 -44.0   0.0\n",
       "...      ...     ...   ...   ...   ...\n",
       "73178  115.0  125292  -4.0  48.0  16.0\n",
       "73179   94.0  127288  -6.0 -42.0  52.0\n",
       "73180   94.0  127358  -6.0 -40.0  54.0\n",
       "73181   94.0  127558  -6.0 -34.0  50.0\n",
       "73182   92.0  127826  -6.0 -26.0  60.0\n",
       "\n",
       "[73183 rows x 5 columns], S{julich_voxels: Unknown}:          0     1     2     3\n",
       "0       61  70.0 -36.0   4.0\n",
       "1       62  70.0 -36.0   6.0\n",
       "2       63  70.0 -36.0   8.0\n",
       "3       64  70.0 -36.0  10.0\n",
       "4       77  70.0 -34.0   2.0\n",
       "..     ...   ...   ...   ...\n",
       "680  14008  52.0  12.0  -6.0\n",
       "681  14052  52.0  14.0  -8.0\n",
       "682  14093  52.0  16.0 -10.0\n",
       "683  14094  52.0  16.0  -8.0\n",
       "684  14133  52.0  18.0 -10.0\n",
       "\n",
       "[685 rows x 4 columns], S{region_voxels: Unknown}:                                     0       1    2     3     4\n",
       "0            Ch 123 (Basal Forebrain)  107765  4.0   2.0 -14.0\n",
       "1            Ch 123 (Basal Forebrain)  107814  4.0   4.0 -12.0\n",
       "2            Ch 123 (Basal Forebrain)  107859  4.0   6.0 -12.0\n",
       "3            Ch 123 (Basal Forebrain)  111875  2.0   4.0 -12.0\n",
       "4            Ch 123 (Basal Forebrain)  111876  2.0   4.0 -10.0\n",
       "...                               ...     ...  ...   ...   ...\n",
       "42821  Fastigial Nucleus (Cerebellum)  118240 -2.0 -58.0 -26.0\n",
       "42822  Fastigial Nucleus (Cerebellum)  118303 -2.0 -56.0 -30.0\n",
       "42823  Fastigial Nucleus (Cerebellum)  118304 -2.0 -56.0 -28.0\n",
       "42824  Fastigial Nucleus (Cerebellum)  118305 -2.0 -56.0 -26.0\n",
       "42825  Fastigial Nucleus (Cerebellum)  118368 -2.0 -54.0 -30.0\n",
       "\n",
       "[42826 rows x 5 columns], S{julich_id: Unknown}:                                         0    1\n",
       "0                Ch 123 (Basal Forebrain)   76\n",
       "1                  Ch 4 (Basal Forebrain)   12\n",
       "2                Ch 123 (Basal Forebrain)   76\n",
       "3                           LB (Amygdala)   90\n",
       "4                           CM (Amygdala)   43\n",
       "..                                    ...  ...\n",
       "117       Interposed Nucleus (Cerebellum)  108\n",
       "118   Dorsal Dentate Nucleus (Cerebellum)   17\n",
       "119  Ventral Dentate Nucleus (Cerebellum)   60\n",
       "120        Fastigial Nucleus (Cerebellum)  101\n",
       "121       Interposed Nucleus (Cerebellum)  108\n",
       "\n",
       "[122 rows x 2 columns]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.feature_selection.univariate_selection module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/neurosynth/base/dataset.py:771: FutureWarning: DataFrame.to_sparse is deprecated and will be removed in a future version\n",
      "  columns=self.data['columns']).to_sparse()\n"
     ]
    }
   ],
   "source": [
    "import stats_helper, datasets_helper\n",
    "from neurolang.frontend.probabilistic_frontend import ProbabilisticFrontend\n",
    "from rdflib import RDFS\n",
    "from nilearn import plotting\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Iterable\n",
    "from neurolang import frontend as fe\n",
    "\n",
    "nl = ProbabilisticFrontend()\n",
    "datasets_helper.load_reverse_inference_dataset(nl)\n",
    "\n",
    "path = 'neurolang_data/ontologies/cogat.xrdf'\n",
    "nl.load_ontology(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_of = nl.new_symbol(name='http://www.obofoundry.org/ro/ro.owl#part_of')\n",
    "subclass_of = nl.new_symbol(name=str(RDFS.subClassOf))\n",
    "label = nl.new_symbol(name=str(RDFS.label))\n",
    "hasTopConcept = nl.new_symbol(name='http://www.w3.org/2004/02/skos/core#hasTopConcept')\n",
    "\n",
    "@nl.add_symbol\n",
    "def word_lower(name: str) -> name:\n",
    "    return name.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/Projects/INRIA/NeuroLang/neurolang/datalog/aggregation.py:152: UserWarning: No check performed. Should implement check for stratified aggregation\n",
      "  \"No check performed. Should implement check for stratified\"\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:4218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from operator import eq\n",
    "\n",
    "with nl.scope as e:\n",
    "    e.julich_to_neurosynth[e.julich_id, e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.xyz_julich[e.x, e.y, e.z, e.julich_id] &\n",
    "        e.xyz_neurosynth[e.x, e.y, e.z, e.id_neurosynth]\n",
    "    )\n",
    "    \n",
    "    e.region_voxels[e.julich_name, e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.julich_id[e.julich_name, e.julich_id] &\n",
    "        e.julich_to_neurosynth[e.julich_id, e.id_neurosynth, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    e.julich_id[e.julich_name, e.id] = (\n",
    "        e.julich_ontology[e.name, 'labelIndex', e.id]\n",
    "    )\n",
    "    \n",
    "    e.julich_voxels[e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.region_voxels['Area TE 3 (STG)', e.id_neurosynth, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    e.p_act[e.id_voxel, e.term] = (\n",
    "        e.p_voxel_study[e.id_voxel, e.id_study] & \n",
    "        e.p_term_study[e.term,  e.id_study] & \n",
    "        e.p_study[e.id_study]\n",
    "    )\n",
    "    \n",
    "    e.ontology_terms[e.onto_name] = (\n",
    "        hasTopConcept[e.uri, 'Perception'] &\n",
    "        label[e.uri, e.onto_name]\n",
    "    )\n",
    "    \n",
    "    e.probability_voxel[e.lower_name] = (\n",
    "        e.p_act[e.id_voxel, e.term] &\n",
    "        e.julich_voxels[e.id_voxel, e.x, e.y, e.z] &\n",
    "        e.ontology_terms[e.term] &\n",
    "        (e.lower_name == word_lower[e.term]\n",
    "    )\n",
    "    \n",
    "    nl_results = nl.solve_query(e.probability_voxel[e.lower_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = nl.new_symbol(name=str(RDFS.label))\n",
    "subclass_of = nl.new_symbol(name=str(RDFS.subClassOf))\n",
    "regional_part = nl.new_symbol(name='http://sig.biostr.washington.edu/fma3.0#regional_part_of')\n",
    "\n",
    "#@nl.add_symbol\n",
    "#def agg_create_region(x: Iterable, y: Iterable, z: Iterable) -> fe.ExplicitVBR:\n",
    "#    mni_t1 = it.masker.volume\n",
    "#    voxels = nib.affines.apply_affine(np.linalg.inv(mni_t1.affine), np.c_[x, y, z])\n",
    "#    return fe.ExplicitVBR(voxels, mni_t1.affine, image_dim=mni_t1.shape)\n",
    "\n",
    "@nl.add_symbol\n",
    "def first_word(name: str) -> str:\n",
    "    return name.split(\" \")[0]\n",
    "\n",
    "with nl.environment as e:    \n",
    "    e.fma_related_region[e.subregion_name, e.fma_uri] = (\n",
    "        label(e.xfma_entity_name, e.fma_uri) & \n",
    "        regional_part(e.fma_region, e.xfma_entity_name) & \n",
    "        subclass_of(e.fma_subregion, e.fma_region) &\n",
    "        label(e.fma_subregion, e.subregion_name)\n",
    "    )\n",
    "    e.fma_related_region[e.recursive_region, e.fma_name] = (\n",
    "        subclass_of(e.recursive_region, e.fma_subregion) & e.fma_related_region(e.fma_subregion, e.fma_name)\n",
    "    )\n",
    "    e.fma_to_destrieux[e.fma_name, e.destrieux_name] = (\n",
    "        label(e.fma_uri, e.fma_name) & e.relation_destrieux_fma(e.destrieux_name, e.fma_name)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gzanitti/Projects/INRIA/NeuroLang/neurolang/datalog/aggregation.py:146: UserWarning: No check performed. Should implement check for stratified aggregation\n",
      "  \"No check performed. Should implement check for stratified\"\n",
      "/Users/gzanitti/miniconda3/envs/neurolang/lib/python3.7/site-packages/pandas/core/frame.py:4218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "with nl.environment as e:\n",
    "    e.region_voxels[e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.fma_related_region[e.fma_subregions, 'Temporal lobe'] & \n",
    "        e.fma_to_destrieux[e.fma_subregions, e.destrieux_name] & \n",
    "        e.destrieux_to_neurosynth[e.destrieux_name, e.id_neurosynth, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    e.destrieux_to_neurosynth[e.destrieux_name, e.id_neurosynth, e.x, e.y, e.z] = (\n",
    "        e.destrieux_labels[e.id_destrieux, e.destrieux_name] &\n",
    "        e.xyz_destrieux[e.x, e.y, e.z, e.id_destrieux] &\n",
    "        e.xyz_neurosynth[e.x, e.y, e.z, e.id_neurosynth]\n",
    "    )\n",
    "    \n",
    "    e.p_act[e.id_voxel, e.term, e.id_study] = (\n",
    "        e.p_voxel_study[e.id_voxel, e.id_study] & \n",
    "        e.p_term_study[e.term,  e.id_study] & \n",
    "        e.p_study[e.id_study]\n",
    "    )\n",
    "    \n",
    "    e.probability_voxel[e.id_voxel, e.x, e.y, e.z] = (\n",
    "        e.p_act[e.id_voxel, e.term, e.id_study] &\n",
    "        e.region_voxels[e.id_voxel, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    #nl_results = nl.solve_all()\n",
    "    nl_results = nl.solve_query(e.probability_voxel[e.id_voxel, e.x, e.y, e.z])\n",
    "    \n",
    "    #e.probability_voxel[nl.symbols.agg_create_region(e.x, e.y, e.z)] = (\n",
    "    #    e.p_act[e.id_voxel, e.term, e.id_study] &\n",
    "    #    e.region_voxels[e.id_voxel, e.x, e.y, e.z]\n",
    "    #)\n",
    "    \n",
    "    #e.final[e.region] = e.probability_voxel[e.region]\n",
    "    \n",
    "    #nl_results = nl.solve_query(e.final[e.region])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = nl_results.value._container.values\n",
    "f = [(float(prob), id_voxel, x, y, z) for z, id_voxel, x, y, prob in t]\n",
    "p_act_aud = nl.add_probabilistic_facts_from_tuples(tuple(f), name='p_act_aud');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_img_nl = datasets_helper.parse_results(nl_results)\n",
    "plotting.plot_stat_map(\n",
    "    prob_img_nl, \n",
    "    title='Tag \"auditory\" (Neurolang)', \n",
    "    cmap='PuBuGn',\n",
    "    display_mode='x',\n",
    "    cut_coords=np.linspace(-63, 63, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    prob_img_nl, title='Tag \"auditory\" (Neurolang)', \n",
    "    cmap='PuBuGn',\n",
    "    display_mode='y',\n",
    "    cut_coords=np.linspace(-30, 5, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import RDF\n",
    "\n",
    "part_of = nl.new_symbol(name='http://www.obofoundry.org/ro/ro.owl#part_of')\n",
    "\n",
    "# Should found a better to imply this\n",
    "triples = nl.symbol_table[nl.get_ontology_triples_symbol().name]\n",
    "a = triples.value.as_numpy_array()\n",
    "t = [('Auditory', str(RDF.type), 'http://www.cognitiveatlas.org/ontology/cogat.owl#CAO_00148')]\n",
    "\n",
    "t = np.concatenate((a, t))\n",
    "nl.add_extensional_predicate_from_tuples(t, name=nl.get_ontology_triples_symbol().name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nl.scope as e:\n",
    "    e.pre_part[e.x, e.y] = part_of[e.x, e.y]\n",
    "\n",
    "    e.perception_terms[e.short_name] = (\n",
    "        e.pre_part[\"Auditory\", e.y] & \n",
    "        subclass_of[e.z, e.y] & \n",
    "        label(e.z, e.term) &\n",
    "        (e.short_name == nl.symbols.first_word(e.term))\n",
    "    )\n",
    "    \n",
    "    e.p_term_given_act[e.term, e.voxid] = (\n",
    "        e.ns_reported_activations[e.study, e.voxid] &\n",
    "        e.perception_terms[e.term] & \n",
    "        e.ns_term_study_associations[e.study, e.term]\n",
    "    )\n",
    "    \n",
    "    e.p_term_g_aud_voxels[e.term] = (\n",
    "        e.p_term_given_act[e.term, e.voxid] &\n",
    "        e.p_act_aud[e.voxid, e.x, e.y, e.z]\n",
    "    )\n",
    "    \n",
    "    nl_reverse = nl.solve_query(e.p_term_g_aud_voxels[e.term])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#prob_terms, prob_voxels, prob_terms_voxels = stats_helper.load_neurosynth_database()\n",
    "prob_img = stats_helper.parse_neurolang_result(result, prob_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    prob_img, \n",
    "    title='Tag \"auditory\" (Neurolang)', \n",
    "    cmap='PuBuGn',\n",
    "    display_mode='x',\n",
    "    cut_coords=np.linspace(-63, 63, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    prob_img, title='Tag \"auditory\" (Neurolang)', \n",
    "    cmap='PuBuGn',\n",
    "    display_mode='y',\n",
    "    cut_coords=np.linspace(-30, 5, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the same result obtained directly from the NeuroSynth database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_img_ns = stats_helper.parse_neurosynth_result(prob_terms_voxels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    prob_img_ns, title='Tag \"auditory\" (Neurosynth)', \n",
    "    cmap='PuBu',\n",
    "    display_mode='x',\n",
    "    cut_coords=np.linspace(-63, 63, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    prob_img_ns, title='Tag \"auditory\" (Neurosynth)', \n",
    "    cmap='PuBu',\n",
    "    display_mode='y',\n",
    "    cut_coords=np.linspace(-30, 5, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can analyze the results by plotting the p-values obtained. Let's start with the NeuroLang results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, p_values_corrected, p_value_image = stats_helper.compute_p_values(prob_img, q=1e-25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(-np.log10(res))\n",
    "plt.axvline(-np.log10(p_values_corrected), c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    p_value_image, \n",
    "    title=r'$-\\log_{10} P$ value (Neurolang)', \n",
    "    threshold=-np.log10(p_values_corrected), \n",
    "    cmap='YlOrRd',\n",
    "    display_mode='x',\n",
    "    cut_coords=np.linspace(-63, 63, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    p_value_image, title=r'$-\\log_{10} P$ value (Neurolang)', \n",
    "    threshold=-np.log10(p_values_corrected),\n",
    "    cmap='YlOrRd',\n",
    "    display_mode='y',\n",
    "    cut_coords=np.linspace(-30, 5, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above results, we can see that the regions have a high specificity and that they focus entirely on our area of interest. Reducing the area of work in this way allows us to minimize variance, enabling us to obtain results with greater statistical power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's do the same with the NeuroSynth results to compare. It is important to mention that the techniques used for the calculation of the p-values, make a comparison against the average of the activations. Bearing this in mind, by decreasing the region to be analyzed and focusing it on the activated region, the average of the activations increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, p_values_corrected, p_value_image = stats_helper.compute_p_values(prob_img_ns, q=1e-25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(-np.log10(res))\n",
    "plt.axvline(-np.log10(p_values_corrected), c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    p_value_image, \n",
    "    title=r'$-\\log_{10} P$ value (NeuroSynth)', \n",
    "    threshold=-np.log10(p_values_corrected), \n",
    "    cmap='YlOrRd',\n",
    "    display_mode='x',\n",
    "    cut_coords=np.linspace(-63, 63, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    p_value_image, title=r'$-\\log_{10} P$ value (NeuroSynth)', \n",
    "    threshold=-np.log10(p_values_corrected),\n",
    "    cmap='YlOrRd',\n",
    "    display_mode='y',\n",
    "    cut_coords=np.linspace(-30, 5, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen above how despite using a restrictive threshold for the p-value ($q<10^{25}$, FDR corrected), in the Neurosynth example there are activations considered statistically significant in the motor cortex that should not be present for the `auditory` tag. Using a prior information in NeuroLang, we are able to remove these false positives and obtain a cleaner result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "[1] Yarkoni, T.: Neurosynth core tools v0.3.1, DOI: 10.5281/zenodo.9925 (2014). <br/>\n",
    "[2] Yarkoni, T., Poldrack, R. A., Nichols, T. E., Van Essen, D. C. & Wager, T. D: Large-scale automated synthesis of human functional neuroimaging data. Nat. Methods 8, 665–670, DOI: 10.1038/nmeth.1635 (2011). <br/>\n",
    "[3] News. Journal of Investigative Medicine 58 (8), 929 (Dec2010). https://doi.org/10.2310/JIM.0b013e3182025955, http://jim.bmj.com/content/58/8/929.abstract <br/>\n",
    "[4] Insel, T. R., Landis, S.C., Collins, F.S.: Research priorities. The NIHBRAIN Initiative. Science (New York, N.Y.) 340 (6133), 687–688 (May  2013). https://doi.org/10.1126/science.1239276 <br/>\n",
    "[5] Markram, H.: The human brain project. Scientific American306(6), 50–55 (Jun2012). https://doi.org/10.1038/scientificamerican0612-50\n",
    "[6] Derrfuss, J. & Mar, R. A. Lost in localization: the need for a universal coordinate database. NeuroImage 48, 1–7, DOI:10.1016/j.neuroimage.2009.01.053 (2009)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "neurolang",
   "language": "python",
   "name": "neurolang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
